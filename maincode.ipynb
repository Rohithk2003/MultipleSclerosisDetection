{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T18:14:15.627084Z",
     "iopub.status.busy": "2024-12-31T18:14:15.625974Z",
     "iopub.status.idle": "2024-12-31T18:14:15.639787Z",
     "shell.execute_reply": "2024-12-31T18:14:15.638819Z",
     "shell.execute_reply.started": "2024-12-31T18:14:15.627053Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class MultiScaleAttention(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, num_heads: int):\n",
    "        super(MultiScaleAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = out_channels // num_heads\n",
    "        self.query = nn.Linear(in_channels, out_channels)\n",
    "        self.key = nn.Linear(in_channels, out_channels)\n",
    "        self.value = nn.Linear(in_channels, out_channels)\n",
    "        self.attention = nn.MultiheadAttention(out_channels, num_heads)\n",
    "        self.layer_norm = nn.LayerNorm(out_channels)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, in_channels, height, width = x.shape\n",
    "        x = x.view(batch_size, in_channels, -1) \n",
    "        x = x.permute(0, 2, 1) \n",
    "        query = self.query(x)\n",
    "        key = self.key(x)\n",
    "        value = self.value(x)\n",
    "        attention_output, _ = self.attention(query, key, value)\n",
    "        attention_output = self.layer_norm(attention_output)  \n",
    "        attention_output = attention_output.permute(0, 2, 1).view(batch_size, -1, height, width)\n",
    "        return attention_output\n",
    "\n",
    "class HybridCNNViT(nn.Module):\n",
    "    def __init__(self, in_channels: int, num_classes: int):\n",
    "        super(HybridCNNViT, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) \n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.multi_scale_attention = MultiScaleAttention(512, 512, 8)\n",
    "        self.residual = nn.Conv2d(512, 512, kernel_size=1, bias=False)\n",
    "        self.classifier_conv = nn.Conv2d(512, num_classes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.maxpool2(x) \n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        attention_output = self.multi_scale_attention(x)\n",
    "        x = x + self.residual(attention_output) \n",
    "        x = self.classifier_conv(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T18:14:15.641387Z",
     "iopub.status.busy": "2024-12-31T18:14:15.641053Z",
     "iopub.status.idle": "2024-12-31T18:14:15.654397Z",
     "shell.execute_reply": "2024-12-31T18:14:15.653736Z",
     "shell.execute_reply.started": "2024-12-31T18:14:15.641355Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_and_pad_images(folder_path, img_size=(128, 128), max_images=None):\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, img_size)\n",
    "            images.append(img)\n",
    "\n",
    "    images = np.array(images)\n",
    "\n",
    "    if max_images is not None and len(images) < max_images:\n",
    "        num_to_pad = max_images - len(images)\n",
    "\n",
    "        pad_indices = np.random.randint(0, len(images), num_to_pad)\n",
    "\n",
    "        padding = images[pad_indices]\n",
    "\n",
    "        images = np.concatenate([images, padding], axis=0)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T18:14:15.656086Z",
     "iopub.status.busy": "2024-12-31T18:14:15.655885Z",
     "iopub.status.idle": "2024-12-31T18:14:25.652742Z",
     "shell.execute_reply": "2024-12-31T18:14:25.650621Z",
     "shell.execute_reply.started": "2024-12-31T18:14:15.656068Z"
    }
   },
   "outputs": [],
   "source": [
    "axial_control_folder = \"/kaggle/input/msdataset/Multiple Sclerosis/Control-Axial\"\n",
    "sagittal_control_folder = \"/kaggle/input/msdataset/Multiple Sclerosis/Control-Sagittal\"\n",
    "axial_ms_folder = \"/kaggle/input/msdataset/Multiple Sclerosis/MS-Axial\"\n",
    "sagittal_ms_folder = \"/kaggle/input/msdataset/Multiple Sclerosis/MS-Sagittal\"\n",
    "\n",
    "\n",
    "max_samples = max(\n",
    "    len(os.listdir(axial_control_folder)),\n",
    "    len(os.listdir(sagittal_control_folder)),\n",
    "    len(os.listdir(axial_ms_folder)),\n",
    "    len(os.listdir(sagittal_ms_folder))\n",
    ")\n",
    "\n",
    "axial_control_images = load_and_pad_images(axial_control_folder, max_images=max_samples)\n",
    "sagittal_control_images = load_and_pad_images(sagittal_control_folder, max_images=max_samples)\n",
    "axial_ms_images = load_and_pad_images(axial_ms_folder, max_images=max_samples)\n",
    "sagittal_ms_images = load_and_pad_images(sagittal_ms_folder, max_images=max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.653257Z",
     "iopub.status.idle": "2024-12-31T18:14:25.653553Z",
     "shell.execute_reply": "2024-12-31T18:14:25.653403Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "from PIL import Image, ImageEnhance\n",
    "import random\n",
    "\n",
    "def apply_dct(image):\n",
    "    dct_image = np.zeros_like(image, dtype=np.float32)\n",
    "    for i in range(3): \n",
    "        dct_image[:, :, i] = dct(dct(image[:, :, i], axis=0, norm='ortho'), axis=1, norm='ortho')\n",
    "    return dct_image\n",
    "\n",
    "def augment_image(image):\n",
    "    image = Image.fromarray(np.uint8(image))\n",
    "    image = ImageEnhance.Brightness(image).enhance(random.uniform(0.8, 1.2))\n",
    "    image = ImageEnhance.Contrast(image).enhance(random.uniform(0.8, 1.2))\n",
    "    image = ImageEnhance.Sharpness(image).enhance(random.uniform(0.8, 1.2))\n",
    "    image = np.array(image)\n",
    "    image = apply_dct(image)\n",
    "    return image\n",
    "\n",
    "def augment_dataset(dataset):\n",
    "    return np.array([augment_image(image) for image in dataset])\n",
    "\n",
    "axial_control_images = augment_dataset(axial_control_images)\n",
    "sagittal_control_images = augment_dataset(sagittal_control_images)\n",
    "axial_ms_images = augment_dataset(axial_ms_images)\n",
    "sagittal_ms_images = augment_dataset(sagittal_ms_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.654212Z",
     "iopub.status.idle": "2024-12-31T18:14:25.654554Z",
     "shell.execute_reply": "2024-12-31T18:14:25.654418Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "control_labels = np.zeros(max_samples * 2  , dtype=np.int64) \n",
    "ms_labels = np.ones(max_samples * 2      , dtype=np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.655235Z",
     "iopub.status.idle": "2024-12-31T18:14:25.655625Z",
     "shell.execute_reply": "2024-12-31T18:14:25.655436Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_weights = torch.tensor([1.69, 0.71], dtype=torch.float32).to(device)\n",
    "data = data = np.concatenate([\n",
    "    axial_control_images,sagittal_control_images, \n",
    "    axial_ms_images, sagittal_ms_images\n",
    "], axis=0)\n",
    "\n",
    "labels = np.concatenate([\n",
    "    control_labels, ms_labels\n",
    "], axis=0)\n",
    "\n",
    "data, labels = shuffle(data, labels, random_state=42)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_data = torch.tensor(train_data, dtype=torch.float32).permute(0, 3, 1, 2) \n",
    "test_data = torch.tensor(test_data, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.657623Z",
     "iopub.status.idle": "2024-12-31T18:14:25.658002Z",
     "shell.execute_reply": "2024-12-31T18:14:25.657827Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, n_classes):\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.arange(n_classes))\n",
    "    \n",
    "    sensitivity = {}\n",
    "    specificity = {}\n",
    "    f1_scores = {}\n",
    "    accuracy = 0\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        TP = cm[i, i]  \n",
    "        FP = cm[:, i].sum() - TP\n",
    "        FN = cm[i, :].sum() - TP \n",
    "        TN = cm.sum() - (TP + FP + FN) \n",
    "\n",
    "        sensitivity[i] = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "\n",
    "        specificity[i] = TN / (TN + FP) if TN + FP > 0 else 0\n",
    "\n",
    "        # Precision\n",
    "        precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "\n",
    "        # F1 Score\n",
    "        f1_scores[i] = 2 * (precision * sensitivity[i]) / (precision + sensitivity[i]) if precision + sensitivity[i] > 0 else 0\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    accuracy = np.trace(cm) / cm.sum()\n",
    "\n",
    "    # Collect metrics in a dictionary\n",
    "    metrics_dict = {\n",
    "        'Sensitivity': sensitivity,\n",
    "        'Specificity': specificity,\n",
    "        'F1 Score': f1_scores,\n",
    "        'Accuracy': accuracy\n",
    "    }\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.658648Z",
     "iopub.status.idle": "2024-12-31T18:14:25.658888Z",
     "shell.execute_reply": "2024-12-31T18:14:25.658789Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "def train_model(train_loader):\n",
    "    model = HybridCNNViT(in_channels=3, num_classes=2)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    model = model.to(device)\n",
    "    model = nn.DataParallel(model)\n",
    "     \n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "        # Calculate accuracy for this epoch\n",
    "        train_accuracy = 100 * correct / total\n",
    "        train_losses.append(total_loss / len(train_loader))\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        scheduler.step()\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}, Accuracy: {train_accuracy}%\")\n",
    "    return model,optimizer,scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.659326Z",
     "iopub.status.idle": "2024-12-31T18:14:25.659655Z",
     "shell.execute_reply": "2024-12-31T18:14:25.659525Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "def test_eval(model, test_loader, n_classes=4):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    metrics = calculate_metrics(true_labels, predictions, n_classes)\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    average_loss = test_loss / len(test_loader)\n",
    "    \n",
    "    print(f\"Test Loss: {average_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Sensitivity: {metrics['Sensitivity']}\")\n",
    "    print(f\"Specificity: {metrics['Specificity']}\")\n",
    "    print(f\"F1 Score: {metrics['F1 Score']}\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']:.2f}\")\n",
    "    \n",
    "    plot_confusion_matrix(predictions, true_labels, class_names=[\"Control Axial\", \"Control Sagittal\", \"MS Axial\", \"MS Sagittal\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.660259Z",
     "iopub.status.idle": "2024-12-31T18:14:25.660569Z",
     "shell.execute_reply": "2024-12-31T18:14:25.660399Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_roc_curve(model, test_loader, device):\n",
    "    \n",
    "    model.eval()  \n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            \n",
    "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "            \n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Count correct predictions\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    true_labels = label_binarize(true_labels, classes=[0, 1])  # For 2 classes\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(true_labels[:, 0], np.array(predictions) == 0)  # Compare class-wise\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'Class 0 (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for Binary Classification')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    return accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.661433Z",
     "iopub.status.idle": "2024-12-31T18:14:25.661823Z",
     "shell.execute_reply": "2024-12-31T18:14:25.661652Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "def plot_roc_pr_curve(model, test_loader, device):\n",
    "    model.eval() \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    true_labels_bin = label_binarize(true_labels, classes=[0, 1, 2, 3])  # For 4 classes\n",
    "    n_classes = 4 \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    pr_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(true_labels_bin[:, i], probs[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        precision[i], recall[i], _ = precision_recall_curve(true_labels_bin[:, i], probs[:, i])\n",
    "        pr_auc[i] = average_precision_score(true_labels_bin[:, i], probs[:, i])\n",
    "\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for 4-Class Classification')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(recall[i], precision[i], lw=2, label=f'Class {i} (AP = {pr_auc[i]:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve for 4-Class Classification')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    return accuracy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.662642Z",
     "iopub.status.idle": "2024-12-31T18:14:25.663014Z",
     "shell.execute_reply": "2024-12-31T18:14:25.662854Z"
    }
   },
   "outputs": [],
   "source": [
    "def measure_inference_time(model, test_loader, device):\n",
    "    model.eval() \n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            break  \n",
    "    \n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "\n",
    "    return inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.663791Z",
     "iopub.status.idle": "2024-12-31T18:14:25.664173Z",
     "shell.execute_reply": "2024-12-31T18:14:25.664014Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MultipleSclerosisDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx].to(device), self.labels[idx].to(device)\n",
    "\n",
    "train_dataset = MultipleSclerosisDataset(train_data, train_labels)\n",
    "test_dataset = MultipleSclerosisDataset(test_data, test_labels)\n",
    "models = []\n",
    "batch_sizes = []\n",
    "inference_times = []\n",
    "for i in [8,16,32,64,40,52,100,128,256,512]:\n",
    "    print(f\"Batch Size : {i}\")\n",
    "    batch_size = i\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    new_model,optimizer,scheduler = train_model(train_loader)\n",
    "    models.append(new_model)\n",
    "    test_eval(new_model,test_loader)\n",
    "    accuracy = plot_roc_curve(new_model, test_loader, device)\n",
    "    inference_time = measure_inference_time(new_model, test_loader, device)\n",
    "    batch_sizes.append(i)\n",
    "    inference_times.append(inference_time)\n",
    "    torch.save({\n",
    "        'batch_size': i, \n",
    "        'model_state_dict': new_model.state_dict(), \n",
    "        'optimizer_state_dict': optimizer.state_dict(), \n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "    }, f'checkpoint{i}.pth')\n",
    "\n",
    "    print(\"Model saved successfully!\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(batch_sizes, inference_times, marker='o', linestyle='-', color='b')\n",
    "plt.title('Model Inference Time vs. Batch Size')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Inference Time (seconds)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.665209Z",
     "iopub.status.idle": "2024-12-31T18:14:25.665530Z",
     "shell.execute_reply": "2024-12-31T18:14:25.665377Z"
    }
   },
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.666568Z",
     "iopub.status.idle": "2024-12-31T18:14:25.666935Z",
     "shell.execute_reply": "2024-12-31T18:14:25.666804Z"
    }
   },
   "outputs": [],
   "source": [
    "main_model = models[0]\n",
    "checkpoint = torch.load('/kaggle/working/checkpoint8.pth')\n",
    "main_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "main_model.eval()  \n",
    "test_loader = DataLoader(test_dataset, batch_size=64,shuffle=True)\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0\n",
    "predictions = []\n",
    "true_labels = []\n",
    "predicted_probs = []  \n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = main_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        probs = torch.softmax(outputs, dim=1)  \n",
    "        predicted_probs.extend(probs.cpu().numpy()) \n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "metrics = calculate_metrics(true_labels, predictions, 2)\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "average_loss = test_loss / len(test_loader)\n",
    "\n",
    "print(f\"Test Loss: {average_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Sensitivity: {metrics['Sensitivity']}\")\n",
    "print(f\"Specificity: {metrics['Specificity']}\")\n",
    "print(f\"F1 Score: {metrics['F1 Score']}\")\n",
    "print(f\"Accuracy: {metrics['Accuracy']:.2f}\")\n",
    "\n",
    "plot_confusion_matrix(predictions, true_labels, class_names=[\"Control\", \"MS\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.667974Z",
     "iopub.status.idle": "2024-12-31T18:14:25.668346Z",
     "shell.execute_reply": "2024-12-31T18:14:25.668184Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curve(y_true, y_scores):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.669376Z",
     "iopub.status.idle": "2024-12-31T18:14:25.669759Z",
     "shell.execute_reply": "2024-12-31T18:14:25.669598Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_probs = np.array(predicted_probs)\n",
    "positive_class_probs = predicted_probs[:, 1] \n",
    "plot_roc_curve(true_labels, positive_class_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.670387Z",
     "iopub.status.idle": "2024-12-31T18:14:25.670785Z",
     "shell.execute_reply": "2024-12-31T18:14:25.670623Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_feature_maps(model, input_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        activations = model.conv1(input_tensor).cpu().numpy() \n",
    "        num_filters = activations.shape[1]\n",
    "        fig, axes = plt.subplots(1, num_filters, figsize=(15, 15))\n",
    "        for i in range(num_filters):\n",
    "            axes[i].imshow(activations[0, i, :, :], cmap='viridis')\n",
    "            axes[i].axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-31T18:14:25.671919Z",
     "iopub.status.idle": "2024-12-31T18:14:25.672209Z",
     "shell.execute_reply": "2024-12-31T18:14:25.672089Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_probs = [tensor for tensor in predicted_probs]\n",
    "all_predicted_probs = np.concatenate(predicted_probs, axis=0)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "if isinstance(predicted_probs, list):\n",
    "    all_predicted_probs = np.concatenate(predicted_probs, axis=0) \n",
    "else:\n",
    "    all_predicted_probs = predicted_probs\n",
    "\n",
    "def plot_histogram(data, title, xlabel, ylabel):\n",
    "    \"\"\"\n",
    "    Helper function to plot a histogram.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(data, kde=True, bins=30, color='blue', edgecolor='black')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(xlabel, fontsize=14)\n",
    "    plt.ylabel(ylabel, fontsize=14)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "# Histogram of predicted probabilities\n",
    "plot_histogram(\n",
    "    all_predicted_probs,\n",
    "    title=\"Histogram of Predicted Probabilities\",\n",
    "    xlabel=\"Probability\",\n",
    "    ylabel=\"Frequency\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6387118,
     "sourceId": 10316870,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6397781,
     "sourceId": 10332651,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6405307,
     "sourceId": 10343697,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 205623,
     "modelInstanceId": 183430,
     "sourceId": 215157,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
